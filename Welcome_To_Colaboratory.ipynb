{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Liki990/Doc/blob/main/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def read_wnut(file_path):\n",
        "    file_path = Path(file_path)\n",
        "\n",
        "    raw_text = file_path.read_text().strip()\n",
        "    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
        "    token_docs = []\n",
        "    tag_docs = []\n",
        "    for doc in raw_docs:\n",
        "        tokens = []\n",
        "        tags = []\n",
        "        for line in doc.split('\\n'):\n",
        "            token, tag = line.split()\n",
        "            tokens.append(token)\n",
        "            tags.append(tag)\n",
        "        token_docs.append(tokens)\n",
        "        tag_docs.append(tags)\n",
        "\n",
        "    return token_docs, tag_docs\n",
        "\n",
        "texts, tags = read_wnut('/content/output_conll.txt')\n",
        "\n",
        "print(texts[2][10:17], tags[2][10:17], sep='\\n')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_tags, val_tags = train_test_split(texts, tags, test_size=.2)\n",
        "\n",
        "unique_tags = set(tag for doc in tags for tag in doc)\n",
        "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
        "id2tag = {id: tag for tag, id in tag2id.items()}\n",
        "\n",
        "from transformers import DistilBertTokenizerFast, TrainingArguments, Trainer\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
        "train_encodings = tokenizer(train_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "val_encodings = tokenizer(val_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def encode_tags(tags, encodings):\n",
        "    labels = [[tag2id[tag] for tag in doc] for doc in tags]\n",
        "    encoded_labels = []\n",
        "\n",
        "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
        "        doc_enc_labels = np.ones(len(doc_offset), dtype=int) * -100\n",
        "\n",
        "        for i, (start, end) in enumerate(doc_offset):\n",
        "            # Check if the token is a real token or a padding token\n",
        "            if start == 0 and end != 0:\n",
        "                doc_enc_labels[i] = doc_labels.pop(0)\n",
        "\n",
        "        encoded_labels.append(doc_enc_labels.tolist())\n",
        "\n",
        "    return encoded_labels\n",
        "\n",
        "train_labels = encode_tags(train_tags, train_encodings)\n",
        "val_labels = encode_tags(val_tags, val_encodings)\n",
        "\n",
        "import torch\n",
        "\n",
        "class MedicalDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_encodings.pop(\"offset_mapping\") # we don't want to pass this to the model\n",
        "val_encodings.pop(\"offset_mapping\")\n",
        "train_dataset =MedicalDataset(train_encodings, train_labels)\n",
        "val_dataset = MedicalDataset(val_encodings, val_labels)\n",
        "\n",
        "from transformers import DistilBertForTokenClassification\n",
        "model = DistilBertForTokenClassification.from_pretrained('distilbert-base-cased', num_labels=len(unique_tags))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./custom_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(\"custom_model\")\n",
        "tokenizer.save_pretrained(\"tokenizer\")\n",
        "\n",
        "import json\n",
        "config = json.load(open(\"custom_model/config.json\"))\n",
        "config[\"id2label\"] = id2tag\n",
        "config[\"label2id\"] = tag2id\n",
        "json.dump(config, open(\"custom_model/config.json\",\"w\"))\n",
        "model_fine_tuned = DistilBertForTokenClassification.from_pretrained(\"custom_model\")\n",
        "from transformers import pipeline\n",
        "nlp = pipeline(\"ner\", model=model_fine_tuned, tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "example =  '''The proband (II-2 in Fig.2) is a 45-year old woman, who first presented to our university hospital at the age of 35 and was referred to us because of her pregnancy.\n",
        "She has congenital deafness, first experienced syncope at the age of 3, and was diagnosed with epilepsy.\n",
        "She was treated with anti-epilepsy medications; however, she subsequently experienced several instances of syncope.\n",
        "At the age of 13, she had a syncope event, and was suspected of having JLNS because of her congenital deafness and prolonged QT interval.\n",
        "Her syncope was diagnosed as an arrhythmic episode when she was aware of tachycardia and as epilepsy when she was not.\n",
        "She also had a subarachnoid hemorrhage at the age of 29.\n",
        "When she first presented at our hospital, she was not taking beta-blockers, because of a history of asthma, but was taking mexiletine in addition to phenytoin.\n",
        "Her QTc was found to be prolonged (584 ms) at presentation and administration of atenolol was initiated.\n",
        "She delivered her baby (III-1 in Fig.2) through Caesarean operation at our hospital at the age of 35.\n",
        "At 37, she delivered her second baby (III-2 in Fig.2) through Caesarean operation at our hospital.\n",
        "Despite administration of beta-blockers, her QTc remained prolonged (600 msec at the age of 37, 780 msec at 44) (Figs.2 and ​3a), which is not unexpected because treatment with beta-blockers in LQTS1 is not expected to overtly reduce QTc [18].\n",
        "However, she continued to experience occasional syncope and finally underwent an implantable cardioverter defibrillator (ICD) operation at 38 years of age.\n",
        "Subsequently, she is in a stable clinical condition.\n",
        "Because the proband was suspected of JLNS and both infants had a measured QTc of 500 ms or greater within 1 month after birth, beta blockers were initiated and both children remain in stable condition at ages 10 and 8 (Figs.2 and 3b, c).\n",
        "QTc of the son (III-1 in Fig.2) was measured as 500 ms one month after birth, while the QTc of his sister (III-2) was 530 ms at birth.\n",
        "The father (I-1) and mother (I-2) of the proband were first cousins.\n",
        "There is no history of sudden unexplained syncope or death of children or adults in the immediate family members, despite the prolonged QTc of the children.\n",
        "Clinical evaluation and consultation of the proband and her family members were performed at Chiba University Hospital.\n",
        "Clinical phenotypes were deduced from the clinical history, physical examinations, and ECG.\n",
        "Blood samples were collected from the proband and her family members following genetic counseling, and written informed consent was obtained prior to sample collection.\n",
        "Genomic DNA was isolated from peripheral blood lymphocytes according to established protocols at our laboratory [19].\n",
        "Entire coding exons, including the intronic boundaries of the genes, of KCNQ1 (NCBI ref: NM_000218) and other LQT causative genes (KCNH2, SCN5A, KCNE1, KCNE2, KCNJ2, SCN4B, KCNJ5) were amplified by polymerase chain reaction (PCR), according to established protocols in our laboratory.\n",
        "Briefly, 30–100 ng of genomic DNA was subjected to PCR amplification with DNA polymerase (PrimeSTAR GXL DNA Polymerase; Takara Bio Inc., Kusatsu, Japan) and primer sets.\n",
        "The amplicons were subjected to conventional sequencing with Sanger sequencers (Applied Biosystems 3730/3130 DNA analyzers; Thermo Fisher Scientific, Waltham, MA, USA).\n",
        "The sequence data were processed with Gene Codes Sequencher Software (Takara Bio Inc.) and mapped to the human genome sequence (build GRCh37/hg19).\n",
        "Genetic analysis was performed to screen all coding exons and the exon–intron boundaries of the KCNQ1 gene (NCBI ref: NM_000218.2, NP_000209.2) with concurrent screening of other LQT causative genes (KCNH2, SCN5A, KCNE1, KCNE2, KCNJ2, SCN4B, KCNJ5).\n",
        "We detected a novel homozygous nonsense variant, NM_000218.2:c.115G > T (p.Glu39X, in exon 1a), in the KCNQ1 gene of the proband, as well as a homozygous common variant (NM_000218.2:c.1343C > G, p.Pro448Arg) (Additional file 1: Table S1).\n",
        "Genetic screening of her mother (I-2) and children (III-1 and III-2) revealed that they were heterozygous for the nonsense variant (Fig.2).\n",
        "Her husband (II-3) was also screened and found to be heterozygous for the common variant (NM_000218.2:c.1343C > G, p.Pro448Arg).\n",
        "The proband is a child from a first-cousin marriage, and we have concluded the homozygous nonsense variant in the proband is the cause of her JLNS1.\n",
        "The proband was negative for pathogenic variants in other LQT causative genes, including the KCNE1 gene (Additional file 1: Table S1).\n",
        "\n",
        "'''\n",
        "\n",
        "ner_results = nlp(example)\n",
        "\n",
        "print(ner_results)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y7TmMtQwo98E",
        "outputId": "b90551e7-466e-4a21-e5d1-f57c3d5284de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['of', 'the', 'Second', 'Affiliated', 'Hospital', 'of', 'Zhejiang']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 02:45, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.293899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.160919</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity': 'B-Weight', 'score': 0.019836947, 'index': 1, 'word': 'The', 'start': 0, 'end': 3}, {'entity': 'B-Route', 'score': 0.018387299, 'index': 2, 'word': 'pro', 'start': 4, 'end': 7}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.021511361, 'index': 3, 'word': '##band', 'start': 7, 'end': 11}, {'entity': 'B-Weight', 'score': 0.020540632, 'index': 6, 'word': '-', 'start': 15, 'end': 16}, {'entity': 'B-Route', 'score': 0.017666437, 'index': 9, 'word': 'Fi', 'start': 21, 'end': 23}, {'entity': 'B-Weight', 'score': 0.019256303, 'index': 10, 'word': '##g', 'start': 23, 'end': 24}, {'entity': 'B-Weight', 'score': 0.020462334, 'index': 11, 'word': '.', 'start': 24, 'end': 25}, {'entity': 'B-Weight', 'score': 0.017643817, 'index': 14, 'word': 'is', 'start': 28, 'end': 30}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018846586, 'index': 15, 'word': 'a', 'start': 31, 'end': 32}, {'entity': 'I-Texture', 'score': 0.01646464, 'index': 16, 'word': '45', 'start': 33, 'end': 35}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.022567762, 'index': 17, 'word': '-', 'start': 35, 'end': 36}, {'entity': 'I-Duraiton', 'score': 0.015773874, 'index': 18, 'word': 'year', 'start': 36, 'end': 40}, {'entity': 'B-Weight', 'score': 0.017265968, 'index': 19, 'word': 'old', 'start': 41, 'end': 44}, {'entity': 'B-Weight', 'score': 0.017344005, 'index': 20, 'word': 'woman', 'start': 45, 'end': 50}, {'entity': 'I-History', 'score': 0.019451981, 'index': 21, 'word': ',', 'start': 50, 'end': 51}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.01807619, 'index': 22, 'word': 'who', 'start': 52, 'end': 55}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.022787737, 'index': 23, 'word': 'first', 'start': 56, 'end': 61}, {'entity': 'B-Weight', 'score': 0.019885793, 'index': 24, 'word': 'presented', 'start': 62, 'end': 71}, {'entity': 'B-Date', 'score': 0.020494912, 'index': 25, 'word': 'to', 'start': 72, 'end': 74}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.019626908, 'index': 27, 'word': 'university', 'start': 79, 'end': 89}, {'entity': 'I-Texture', 'score': 0.01980838, 'index': 28, 'word': 'hospital', 'start': 90, 'end': 98}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.019943133, 'index': 30, 'word': 'the', 'start': 102, 'end': 105}, {'entity': 'B-Weight', 'score': 0.016728122, 'index': 31, 'word': 'age', 'start': 106, 'end': 109}, {'entity': 'I-History', 'score': 0.01882097, 'index': 32, 'word': 'of', 'start': 110, 'end': 112}, {'entity': 'B-Lab_value', 'score': 0.017896652, 'index': 33, 'word': '35', 'start': 113, 'end': 115}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.01998719, 'index': 34, 'word': 'and', 'start': 116, 'end': 119}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.020043556, 'index': 35, 'word': 'was', 'start': 120, 'end': 123}, {'entity': 'B-Height', 'score': 0.019649763, 'index': 37, 'word': 'to', 'start': 133, 'end': 135}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018962534, 'index': 40, 'word': 'of', 'start': 147, 'end': 149}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.020621838, 'index': 41, 'word': 'her', 'start': 150, 'end': 153}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.01834302, 'index': 42, 'word': 'pregnancy', 'start': 154, 'end': 163}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.021107892, 'index': 44, 'word': 'She', 'start': 165, 'end': 168}, {'entity': 'B-Disease_disorder', 'score': 0.022617912, 'index': 46, 'word': 'con', 'start': 173, 'end': 176}, {'entity': 'B-Month', 'score': 0.019626252, 'index': 48, 'word': '##ital', 'start': 179, 'end': 183}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.020766107, 'index': 49, 'word': 'deaf', 'start': 184, 'end': 188}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.028231198, 'index': 50, 'word': '##ness', 'start': 188, 'end': 192}, {'entity': 'I-Biological_structure', 'score': 0.018455535, 'index': 51, 'word': ',', 'start': 192, 'end': 193}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.021497456, 'index': 52, 'word': 'first', 'start': 194, 'end': 199}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.021011822, 'index': 54, 'word': 's', 'start': 212, 'end': 213}, {'entity': 'B-Month', 'score': 0.022836177, 'index': 55, 'word': '##ync', 'start': 213, 'end': 216}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.024408553, 'index': 56, 'word': '##ope', 'start': 216, 'end': 219}, {'entity': 'B-Route', 'score': 0.016905623, 'index': 57, 'word': 'at', 'start': 220, 'end': 222}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018803729, 'index': 58, 'word': 'the', 'start': 223, 'end': 226}, {'entity': 'I-History', 'score': 0.018888377, 'index': 59, 'word': 'age', 'start': 227, 'end': 230}, {'entity': 'I-History', 'score': 0.0192197, 'index': 60, 'word': 'of', 'start': 231, 'end': 233}, {'entity': 'B-Route', 'score': 0.018472651, 'index': 61, 'word': '3', 'start': 234, 'end': 235}, {'entity': 'I-History', 'score': 0.020984445, 'index': 62, 'word': ',', 'start': 235, 'end': 236}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.01951865, 'index': 63, 'word': 'and', 'start': 237, 'end': 240}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.017193498, 'index': 64, 'word': 'was', 'start': 241, 'end': 244}, {'entity': 'B-Weight', 'score': 0.016582714, 'index': 67, 'word': 'e', 'start': 260, 'end': 261}, {'entity': 'B-Biological_attribute', 'score': 0.018092547, 'index': 68, 'word': '##pile', 'start': 261, 'end': 265}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.024094, 'index': 69, 'word': '##psy', 'start': 265, 'end': 268}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.02051284, 'index': 71, 'word': 'She', 'start': 270, 'end': 273}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.017474076, 'index': 72, 'word': 'was', 'start': 274, 'end': 277}, {'entity': 'B-Weight', 'score': 0.018715406, 'index': 75, 'word': 'anti', 'start': 291, 'end': 295}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.020336721, 'index': 76, 'word': '-', 'start': 295, 'end': 296}, {'entity': 'I-Age', 'score': 0.017618794, 'index': 77, 'word': 'e', 'start': 296, 'end': 297}, {'entity': 'B-Biological_attribute', 'score': 0.017638158, 'index': 78, 'word': '##pile', 'start': 297, 'end': 301}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.021343619, 'index': 79, 'word': '##psy', 'start': 301, 'end': 304}, {'entity': 'I-Disease-disorder', 'score': 0.01869862, 'index': 81, 'word': ';', 'start': 316, 'end': 317}, {'entity': 'B-Weight', 'score': 0.01731115, 'index': 82, 'word': 'however', 'start': 318, 'end': 325}, {'entity': 'I-History', 'score': 0.02063048, 'index': 83, 'word': ',', 'start': 325, 'end': 326}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.016095873, 'index': 84, 'word': 'she', 'start': 327, 'end': 330}, {'entity': 'B-Weight', 'score': 0.018759979, 'index': 88, 'word': 'instances', 'start': 364, 'end': 373}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018919807, 'index': 90, 'word': 's', 'start': 377, 'end': 378}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.023059318, 'index': 92, 'word': '##ope', 'start': 381, 'end': 384}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.01961369, 'index': 95, 'word': 'the', 'start': 389, 'end': 392}, {'entity': 'I-History', 'score': 0.017313356, 'index': 96, 'word': 'age', 'start': 393, 'end': 396}, {'entity': 'I-History', 'score': 0.018433923, 'index': 97, 'word': 'of', 'start': 397, 'end': 399}, {'entity': 'I-History', 'score': 0.021390084, 'index': 99, 'word': ',', 'start': 402, 'end': 403}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.022765279, 'index': 105, 'word': '##ope', 'start': 418, 'end': 421}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018032812, 'index': 106, 'word': 'event', 'start': 422, 'end': 427}, {'entity': 'I-History', 'score': 0.018351596, 'index': 107, 'word': ',', 'start': 427, 'end': 428}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018528977, 'index': 108, 'word': 'and', 'start': 429, 'end': 432}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018461805, 'index': 113, 'word': 'J', 'start': 457, 'end': 458}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.017713895, 'index': 114, 'word': '##L', 'start': 458, 'end': 459}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.019254375, 'index': 115, 'word': '##NS', 'start': 459, 'end': 461}, {'entity': 'B-Height', 'score': 0.018465046, 'index': 117, 'word': 'of', 'start': 470, 'end': 472}, {'entity': 'B-Weight', 'score': 0.0197638, 'index': 122, 'word': 'deaf', 'start': 488, 'end': 492}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.024192754, 'index': 123, 'word': '##ness', 'start': 492, 'end': 496}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.017558904, 'index': 126, 'word': 'Q', 'start': 511, 'end': 512}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.022162799, 'index': 128, 'word': 'interval', 'start': 514, 'end': 522}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.023358686, 'index': 133, 'word': '##ope', 'start': 532, 'end': 535}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.020333434, 'index': 138, 'word': 'a', 'start': 556, 'end': 557}, {'entity': 'I-Biological_structure', 'score': 0.017638821, 'index': 139, 'word': '##rr', 'start': 557, 'end': 559}, {'entity': 'B-Age', 'score': 0.017806344, 'index': 140, 'word': '##hy', 'start': 559, 'end': 561}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.020961381, 'index': 141, 'word': '##th', 'start': 561, 'end': 563}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.025220674, 'index': 142, 'word': '##mic', 'start': 563, 'end': 566}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.021508733, 'index': 143, 'word': 'episode', 'start': 567, 'end': 574}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018395117, 'index': 145, 'word': 'she', 'start': 580, 'end': 583}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.01843969, 'index': 146, 'word': 'was', 'start': 584, 'end': 587}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018001258, 'index': 148, 'word': 'of', 'start': 594, 'end': 596}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.022912726, 'index': 149, 'word': 'ta', 'start': 597, 'end': 599}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.025145903, 'index': 150, 'word': '##chy', 'start': 599, 'end': 602}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.022992913, 'index': 151, 'word': '##card', 'start': 602, 'end': 606}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.027979169, 'index': 152, 'word': '##ia', 'start': 606, 'end': 608}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.021127082, 'index': 153, 'word': 'and', 'start': 609, 'end': 612}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.021695726, 'index': 157, 'word': '##psy', 'start': 621, 'end': 624}, {'entity': 'I-History', 'score': 0.01981191, 'index': 158, 'word': 'when', 'start': 625, 'end': 629}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.0181023, 'index': 159, 'word': 'she', 'start': 630, 'end': 633}, {'entity': 'I-History', 'score': 0.019784916, 'index': 160, 'word': 'was', 'start': 634, 'end': 637}, {'entity': 'B-sex', 'score': 0.016939042, 'index': 161, 'word': 'not', 'start': 638, 'end': 641}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.019137384, 'index': 163, 'word': 'She', 'start': 643, 'end': 646}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.020812558, 'index': 167, 'word': 'sub', 'start': 658, 'end': 661}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.029773375, 'index': 168, 'word': '##ara', 'start': 661, 'end': 664}, {'entity': 'B-Grade', 'score': 0.018415123, 'index': 169, 'word': '##ch', 'start': 664, 'end': 666}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.021845536, 'index': 171, 'word': '##id', 'start': 668, 'end': 670}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.01915065, 'index': 172, 'word': 'hem', 'start': 671, 'end': 674}, {'entity': 'B-sex', 'score': 0.022108154, 'index': 173, 'word': '##or', 'start': 674, 'end': 676}, {'entity': 'B-Grade', 'score': 0.024256568, 'index': 174, 'word': '##r', 'start': 676, 'end': 677}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.02116944, 'index': 175, 'word': '##hage', 'start': 677, 'end': 681}, {'entity': 'B-Weight', 'score': 0.019737963, 'index': 177, 'word': 'the', 'start': 685, 'end': 688}, {'entity': 'I-History', 'score': 0.018800361, 'index': 178, 'word': 'age', 'start': 689, 'end': 692}, {'entity': 'I-History', 'score': 0.019999232, 'index': 179, 'word': 'of', 'start': 693, 'end': 695}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.01825332, 'index': 182, 'word': 'When', 'start': 700, 'end': 704}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018281717, 'index': 183, 'word': 'she', 'start': 705, 'end': 708}, {'entity': 'B-Weight', 'score': 0.01973094, 'index': 184, 'word': 'first', 'start': 709, 'end': 714}, {'entity': 'B-Weight', 'score': 0.01925892, 'index': 185, 'word': 'presented', 'start': 715, 'end': 724}, {'entity': 'B-sex', 'score': 0.017496489, 'index': 186, 'word': 'at', 'start': 725, 'end': 727}, {'entity': 'I-Texture', 'score': 0.019028878, 'index': 188, 'word': 'hospital', 'start': 732, 'end': 740}, {'entity': 'I-History', 'score': 0.019466339, 'index': 189, 'word': ',', 'start': 740, 'end': 741}, {'entity': 'B-Weight', 'score': 0.01662913, 'index': 190, 'word': 'she', 'start': 742, 'end': 745}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018913604, 'index': 191, 'word': 'was', 'start': 746, 'end': 749}, {'entity': 'B-Weight', 'score': 0.023961755, 'index': 194, 'word': 'beta', 'start': 761, 'end': 765}, {'entity': 'I-Detailed_description', 'score': 0.017687988, 'index': 196, 'word': 'block', 'start': 766, 'end': 771}, {'entity': 'B-sex', 'score': 0.01602356, 'index': 198, 'word': ',', 'start': 774, 'end': 775}, {'entity': 'B-Medication', 'score': 0.01661574, 'index': 199, 'word': 'because', 'start': 776, 'end': 783}, {'entity': 'B-Medication', 'score': 0.016528308, 'index': 200, 'word': 'of', 'start': 784, 'end': 786}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018276589, 'index': 201, 'word': 'a', 'start': 787, 'end': 788}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.019090975, 'index': 202, 'word': 'history', 'start': 789, 'end': 796}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.019251583, 'index': 204, 'word': 'as', 'start': 800, 'end': 802}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.0200461, 'index': 205, 'word': '##th', 'start': 802, 'end': 804}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018134363, 'index': 206, 'word': '##ma', 'start': 804, 'end': 806}, {'entity': 'I-History', 'score': 0.018312631, 'index': 207, 'word': ',', 'start': 806, 'end': 807}, {'entity': 'I-weight', 'score': 0.01928562, 'index': 208, 'word': 'but', 'start': 808, 'end': 811}, {'entity': 'B-Female', 'score': 0.023305235, 'index': 211, 'word': 'me', 'start': 823, 'end': 825}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.020361796, 'index': 213, 'word': '##let', 'start': 827, 'end': 830}, {'entity': 'B-Detailed_description', 'score': 0.020594835, 'index': 218, 'word': 'p', 'start': 849, 'end': 850}, {'entity': 'B-Age', 'score': 0.019099865, 'index': 220, 'word': '##yt', 'start': 853, 'end': 855}, {'entity': 'I-History', 'score': 0.019454136, 'index': 235, 'word': '##4', 'start': 897, 'end': 898}, {'entity': 'B-Size', 'score': 0.01822166, 'index': 236, 'word': 'm', 'start': 899, 'end': 900}, {'entity': 'B-Female', 'score': 0.023084026, 'index': 244, 'word': 'ate', 'start': 941, 'end': 944}, {'entity': 'I-Detailed_description', 'score': 0.01966064, 'index': 247, 'word': '##l', 'start': 948, 'end': 949}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.019208746, 'index': 251, 'word': 'She', 'start': 965, 'end': 968}, {'entity': 'I-Anaesthesia', 'score': 0.020061893, 'index': 261, 'word': '##g', 'start': 1000, 'end': 1001}, {'entity': 'B-Weight', 'score': 0.018679291, 'index': 262, 'word': '.', 'start': 1001, 'end': 1002}, {'entity': 'I-Medication', 'score': 0.017265849, 'index': 266, 'word': 'Caesar', 'start': 1013, 'end': 1019}, {'entity': 'I-Texture', 'score': 0.019880118, 'index': 271, 'word': 'hospital', 'start': 1040, 'end': 1048}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.020649599, 'index': 273, 'word': 'the', 'start': 1052, 'end': 1055}, {'entity': 'I-History', 'score': 0.01799026, 'index': 274, 'word': 'age', 'start': 1056, 'end': 1059}, {'entity': 'I-History', 'score': 0.019897997, 'index': 275, 'word': 'of', 'start': 1060, 'end': 1062}, {'entity': 'B-Lab_value', 'score': 0.020074297, 'index': 276, 'word': '35', 'start': 1063, 'end': 1065}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.017315272, 'index': 278, 'word': 'At', 'start': 1067, 'end': 1069}, {'entity': 'I-Anaesthesia', 'score': 0.020392327, 'index': 292, 'word': '##g', 'start': 1116, 'end': 1117}, {'entity': 'B-Weight', 'score': 0.019044803, 'index': 293, 'word': '.', 'start': 1117, 'end': 1118}, {'entity': 'B-Female', 'score': 0.01761197, 'index': 297, 'word': 'Caesar', 'start': 1129, 'end': 1135}, {'entity': 'I-Age', 'score': 0.023322677, 'index': 298, 'word': '##ean', 'start': 1135, 'end': 1138}, {'entity': 'B-Route', 'score': 0.018601589, 'index': 299, 'word': 'operation', 'start': 1139, 'end': 1148}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.018634668, 'index': 300, 'word': 'at', 'start': 1149, 'end': 1151}, {'entity': 'I-Texture', 'score': 0.017453145, 'index': 302, 'word': 'hospital', 'start': 1156, 'end': 1164}, {'entity': 'B-Weight', 'score': 0.023047775, 'index': 305, 'word': 'administration', 'start': 1174, 'end': 1188}, {'entity': 'B-Weight', 'score': 0.024713602, 'index': 307, 'word': 'beta', 'start': 1192, 'end': 1196}, {'entity': 'I-Detailed_description', 'score': 0.018265406, 'index': 309, 'word': 'block', 'start': 1197, 'end': 1202}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.02167158, 'index': 310, 'word': '##ers', 'start': 1202, 'end': 1205}, {'entity': 'I-Distance', 'score': 0.021281369, 'index': 319, 'word': '600', 'start': 1235, 'end': 1238}, {'entity': 'I-Age', 'score': 0.018002154, 'index': 320, 'word': 'm', 'start': 1239, 'end': 1240}, {'entity': 'B-Diagnostic_Procedure', 'score': 0.021267317, 'index': 324, 'word': 'the', 'start': 1247, 'end': 1250}, {'entity': 'B-Weight', 'score': 0.018103687, 'index': 325, 'word': 'age', 'start': 1251, 'end': 1254}, {'entity': 'I-Detailed_description', 'score': 0.016827192, 'index': 326, 'word': 'of', 'start': 1255, 'end': 1257}, {'entity': 'I-Detailed_description', 'score': 0.018809943, 'index': 328, 'word': ',', 'start': 1260, 'end': 1261}, {'entity': 'I-Age', 'score': 0.01859559, 'index': 331, 'word': 'm', 'start': 1266, 'end': 1267}, {'entity': 'I-Dosage', 'score': 0.018947918, 'index': 339, 'word': '##gs', 'start': 1281, 'end': 1283}, {'entity': 'I-Disease-disorder', 'score': 0.02064082, 'index': 347, 'word': 'which', 'start': 1296, 'end': 1301}, {'entity': 'B-Height', 'score': 0.019580172, 'index': 348, 'word': 'is', 'start': 1302, 'end': 1304}, {'entity': 'I-Disease-disorder', 'score': 0.021218503, 'index': 349, 'word': 'not', 'start': 1305, 'end': 1308}, {'entity': 'B-Height', 'score': 0.017192323, 'index': 351, 'word': 'because', 'start': 1320, 'end': 1327}, {'entity': 'B-Medication', 'score': 0.018309899, 'index': 352, 'word': 'treatment', 'start': 1328, 'end': 1337}, {'entity': 'B-Weight', 'score': 0.024115738, 'index': 354, 'word': 'beta', 'start': 1343, 'end': 1347}, {'entity': 'I-Detailed_description', 'score': 0.018127559, 'index': 356, 'word': 'block', 'start': 1348, 'end': 1353}, {'entity': 'I-Disease-disorder', 'score': 0.022460379, 'index': 358, 'word': 'in', 'start': 1357, 'end': 1359}, {'entity': 'B-Route', 'score': 0.016236132, 'index': 359, 'word': 'L', 'start': 1360, 'end': 1361}, {'entity': 'B-Administration', 'score': 0.017036647, 'index': 360, 'word': '##Q', 'start': 1361, 'end': 1362}, {'entity': 'I-Disease-disorder', 'score': 0.017634012, 'index': 363, 'word': 'is', 'start': 1366, 'end': 1368}, {'entity': 'I-Disease-disorder', 'score': 0.020545317, 'index': 364, 'word': 'not', 'start': 1369, 'end': 1372}, {'entity': 'I-Disease-disorder', 'score': 0.019975562, 'index': 366, 'word': 'to', 'start': 1382, 'end': 1384}, {'entity': 'B-Administration', 'score': 0.016387379, 'index': 370, 'word': 'Q', 'start': 1400, 'end': 1401}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ... (your existing code)\n",
        "\n",
        "# Assuming ner_results is a list of dictionaries with keys: 'entity', 'score', 'index', 'word', 'start', 'end'\n",
        "# Example ner_results:\n",
        "# ner_results = [{'entity': 'I-Sign_symptom', 'score': 0.020426337, 'index': 1, 'word': 'A', 'start': 0, 'end': 1}, ...]\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "df = pd.DataFrame(ner_results)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('ner_results.csv', index=False)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "H3iKJysVs89K",
        "outputId": "b243efc5-8b2d-4670-e253-680a1c50d435",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      entity     score  index    word  start   end\n",
            "0             I-Sign_symptom  0.020426      1       A      0     1\n",
            "1             I-Sign_symptom  0.017613      2      28      2     4\n",
            "2     B-Biological_structure  0.017797      3       -      4     5\n",
            "3                    B-Color  0.021427      4    year      5     9\n",
            "4                 I-Activity  0.019883      5       -      9    10\n",
            "..                       ...       ...    ...     ...    ...   ...\n",
            "433           I-Sign_symptom  0.017862    447     the   1666  1669\n",
            "434           I-Sign_symptom  0.019519    448       a   1670  1671\n",
            "435   I-Biological_attribute  0.021289    449   ##bla   1671  1674\n",
            "436  I-Therapeutic_procedure  0.018906    450  ##tion   1674  1678\n",
            "437               I-Activity  0.016707    451       .   1678  1679\n",
            "\n",
            "[438 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# ... (your existing code)\n",
        "\n",
        "# Assuming ner_results is a list of dictionaries with keys: 'entity', 'score', 'index', 'word', 'start', 'end'\n",
        "# Example ner_results:\n",
        "# ner_results = [{'entity': 'I-Sign_symptom', 'score': 0.020426337, 'index': 1, 'word': 'A', 'start': 0, 'end': 1}, ...]\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "df = pd.DataFrame(ner_results)\n",
        "\n",
        "# Generate a unique file name based on the current timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "csv_file_name = f'ner_results_{timestamp}.csv'\n",
        "\n",
        "# Save the DataFrame to the CSV file\n",
        "df.to_csv(csv_file_name, index=False)\n",
        "\n",
        "# Print the file name for reference\n",
        "print(f\"CSV file saved: {csv_file_name}\")\n"
      ],
      "metadata": {
        "id": "3ZbHjobEtThG",
        "outputId": "f90020a7-0f2a-4ac8-ee81-7bc97caa8e4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file saved: ner_results_20231218113503.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# ... (your existing code)\n",
        "\n",
        "# Assuming ner_results is a list of dictionaries with keys: 'entity', 'score', 'index', 'word', 'start', 'end'\n",
        "# Example ner_results:\n",
        "# ner_results = [{'entity': 'I-Sign_symptom', 'score': 0.020426337, 'index': 1, 'word': 'A', 'start': 0, 'end': 1}, ...]\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "df = pd.DataFrame(ner_results)\n",
        "\n",
        "# Generate a unique file name based on the current timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "excel_file_name = f'ner_results_{timestamp}.xlsx'\n",
        "\n",
        "# Save the DataFrame to the Excel file\n",
        "df.to_excel(excel_file_name, index=False)\n",
        "\n",
        "# Print the file name for reference\n",
        "print(f\"Excel file saved: {excel_file_name}\")\n"
      ],
      "metadata": {
        "id": "iu7TzudVtta2",
        "outputId": "188cc94d-e693-4890-82c7-5e06ff04d295",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excel file saved: ner_results_20231218114752.xlsx\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}