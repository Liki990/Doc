{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Liki990/Doc/blob/main/MC_TV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "xQvJG8WcRmZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "5rb_sc2nQxLU",
        "outputId": "fa79fef4-16fc-4cc3-f460-3d0151ab8cce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip -q install transformers"
      ],
      "metadata": {
        "id": "7P1SWB_URC5g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "import torch\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from transformers import (\n",
        "    MODEL_WITH_LM_HEAD_MAPPING,\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModelWithLMHead,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter\n",
        "\n",
        "# Configs\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n",
        "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
        "model = AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-small\")"
      ],
      "metadata": {
        "id": "3FFqyc4CRI-E",
        "outputId": "3c8dbb4c-1a99-44aa-e79e-9433875613ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:1581: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cache Setup**"
      ],
      "metadata": {
        "id": "wqf_02dSaszL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Args():\n",
        "    def __init__(self):\n",
        "        self.output_dir = 'output-small-save'\n",
        "        self.model_type = 'gpt2'\n",
        "        self.model_name_or_path = 'microsoft/DialoGPT-small'\n",
        "        self.config_name = 'microsoft/DialoGPT-small'\n",
        "        self.tokenizer_name = 'microsoft/DialoGPT-small'\n",
        "        self.cache_dir = 'cached'\n",
        "        self.block_size = 512\n",
        "        self.do_train = True\n",
        "        self.do_eval = True\n",
        "        self.evaluate_during_training = False\n",
        "        self.per_gpu_train_batch_size = 4\n",
        "        self.per_gpu_eval_batch_size = 4\n",
        "        self.gradient_accumulation_steps = 1\n",
        "        self.learning_rate = 5e-5\n",
        "        self.weight_decay = 0.0\n",
        "        self.adam_epsilon = 1e-8\n",
        "        self.max_grad_norm = 1.0\n",
        "        self.num_train_epochs = 3\n",
        "        self.max_steps = -1\n",
        "        self.warmup_steps = 0\n",
        "        self.logging_steps = 1000\n",
        "        self.save_steps = 3500\n",
        "        self.save_total_limit = None\n",
        "        self.eval_all_checkpoints = False\n",
        "        self.no_cuda = False\n",
        "        self.overwrite_output_dir = True\n",
        "        self.overwrite_cache = True\n",
        "        self.should_continue = False\n",
        "        self.seed = 42\n",
        "        self.local_rank = -1\n",
        "        self.fp16 = False\n",
        "        self.fp16_opt_level = 'O1'\n",
        "\n",
        "args = Args()\n",
        "\n",
        "\n",
        "\n",
        "def construct_conv(row, tokenizer, eos = True):\n",
        "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "    conv = list(reversed([tokenizer.encode(x) + [tokenizer.eos_token_id] for x in row]))\n",
        "    conv = flatten(conv)\n",
        "    return conv\n",
        "\n",
        "class ConversationDataset(Dataset):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer, args, df, block_size=512):\n",
        "\n",
        "        block_size = block_size - (tokenizer.model_max_length - tokenizer.max_len_single_sentence)\n",
        "\n",
        "        directory = args.cache_dir\n",
        "        cached_features_file = os.path.join(\n",
        "            directory, args.model_type + \"_cached_lm_\" + str(block_size)\n",
        "        )\n",
        "\n",
        "        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
        "            logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "            with open(cached_features_file, \"rb\") as handle:\n",
        "                self.examples = pickle.load(handle)\n",
        "        else:\n",
        "            logger.info(\"Creating features from dataset file at %s\", directory)\n",
        "\n",
        "            self.examples = []\n",
        "            for _, row in df.iterrows():\n",
        "                conv = construct_conv(row, tokenizer)\n",
        "                self.examples.append(conv)\n",
        "                logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "            with open(cached_features_file, \"wb\") as handle:\n",
        "                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return torch.tensor(self.examples[item], dtype=torch.long)\n",
        "\n",
        "\n",
        "def load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False):\n",
        "    return ConversationDataset(tokenizer, args, df_val if evaluate else df_trn)\n",
        "\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "\n",
        "def _sorted_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> List[str]:\n",
        "    ordering_and_checkpoint_path = []\n",
        "\n",
        "    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n",
        "\n",
        "    for path in glob_checkpoints:\n",
        "        if use_mtime:\n",
        "            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n",
        "        else:\n",
        "            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n",
        "            if regex_match and regex_match.groups():\n",
        "                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n",
        "\n",
        "    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n",
        "    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n",
        "    return checkpoints_sorted\n",
        "def _rotate_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> None:\n",
        "    if not args.save_total_limit:\n",
        "        return\n",
        "    if args.save_total_limit <= 0:\n",
        "        return\n",
        "\n",
        "    # Check if we should delete older checkpoint(s)\n",
        "    checkpoints_sorted = _sorted_checkpoints(args, checkpoint_prefix, use_mtime)\n",
        "    if len(checkpoints_sorted) <= args.save_total_limit:\n",
        "        return\n",
        "\n",
        "    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n",
        "    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n",
        "    for checkpoint in checkpoints_to_be_deleted:\n",
        "        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n",
        "        shutil.rmtree(checkpoint)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q-KoWqQSavCT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lets Chat for 5 Lines**"
      ],
      "metadata": {
        "id": "GTbB1mzqRkGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's chat for 5 lines\n",
        "for step in range(5):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens\n",
        "    chat_history_ids = model.generate(\n",
        "    bot_input_ids, max_length=1000,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # pretty print last ouput tokens from bot\n",
        "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n"
      ],
      "metadata": {
        "id": "LqsSnhuVRx0f",
        "outputId": "d9c27697-76e1-4d54-b32d-cceb4438dbba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> User:Hi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DialoGPT: Hi\n",
            ">> User:Having Cold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DialoGPT: I'm having a cold\n",
            ">> User:Having Fever\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DialoGPT: Having a cold\n",
            ">> User:Having dizziness\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DialoGPT: Having a headache\n",
            ">> User:bye\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DialoGPT: I'm having a headache\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loading**"
      ],
      "metadata": {
        "id": "T3WCqzv5UXda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "f_train = open(\"/content/drive/MyDrive/data/train_data.json\")\n",
        "train_data = json.load(f_train)\n",
        "f_train.close()\n",
        "# print(len(train_data))\n",
        "\n",
        "\n",
        "f_validate = open(\"/content/drive/MyDrive/data/validate_data.json\")\n",
        "validate_data = json.load(f_validate)\n",
        "f_validate.close()\n",
        "# print(len(validate_data))"
      ],
      "metadata": {
        "id": "2pKlwwbrTKB1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating DataFrames**"
      ],
      "metadata": {
        "id": "ZdiHgshJVmfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_contexted = []\n",
        "train_data = train_data\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "  row = []\n",
        "  row.append(train_data[i][1])\n",
        "  row.append(train_data[i][0])\n",
        "  train_contexted.append(row)\n",
        "\n",
        "  validate_contexted = []\n",
        "\n",
        "for i in range(len(validate_data)):\n",
        "  row = []\n",
        "  row.append(validate_data[i][1])\n",
        "  row.append(validate_data[i][0])\n",
        "  validate_contexted.append(row)"
      ],
      "metadata": {
        "id": "2eujv2tPU5YX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['response', 'context']\n",
        "columns = columns + ['context/'+str(i) for i in range(0)]\n",
        "columns"
      ],
      "metadata": {
        "id": "8O24rAcyU_Vw",
        "outputId": "96133e27-833e-4845-f4b5-9aeaf234a2bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['response', 'context']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_contexted)\n",
        "trn_df = pd.DataFrame.from_records(train_contexted, columns=columns)\n",
        "trn_df.head(5)"
      ],
      "metadata": {
        "id": "NgqV7vCkVKG7",
        "outputId": "279bc7e6-99d6-4824-c514-1c44502ce9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            response  \\\n",
              "0  Hello, based on your symptoms and examination ...   \n",
              "1  Based on your history and imaging findings, it...   \n",
              "2  Based on your symptoms and medical history, it...   \n",
              "3  Based on your description, it's possible that ...   \n",
              "4  Based on your history and symptoms, it's possi...   \n",
              "\n",
              "                                             context  \n",
              "0  Hello doctor, I've been experiencing palpitati...  \n",
              "1  Hello doctor, I'm a 34-year-old man experienci...  \n",
              "2  Hello doctor, I'm a 23-year-old male with a hi...  \n",
              "3  Hello doctor, I underwent rhinoplasty under ge...  \n",
              "4  Hello doctor, I recently returned from a trip ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd4347d4-dddd-4b05-b793-22aaf7bc493e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hello, based on your symptoms and examination ...</td>\n",
              "      <td>Hello doctor, I've been experiencing palpitati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Based on your history and imaging findings, it...</td>\n",
              "      <td>Hello doctor, I'm a 34-year-old man experienci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Based on your symptoms and medical history, it...</td>\n",
              "      <td>Hello doctor, I'm a 23-year-old male with a hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Based on your description, it's possible that ...</td>\n",
              "      <td>Hello doctor, I underwent rhinoplasty under ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Based on your history and symptoms, it's possi...</td>\n",
              "      <td>Hello doctor, I recently returned from a trip ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd4347d4-dddd-4b05-b793-22aaf7bc493e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd4347d4-dddd-4b05-b793-22aaf7bc493e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd4347d4-dddd-4b05-b793-22aaf7bc493e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a850f445-1435-449a-a0de-2d53fb4801cf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a850f445-1435-449a-a0de-2d53fb4801cf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a850f445-1435-449a-a0de-2d53fb4801cf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "trn_df",
              "summary": "{\n  \"name\": \"trn_df\",\n  \"rows\": 75,\n  \"fields\": [\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          \"Based on your history and symptoms, it's possible that you may have contracted an infection from consuming raw pork, known as Streptococcus suis infection. This bacterial infection can cause symptoms such as fever, headache, and meningitis, particularly in individuals with a history of consuming undercooked pork products. It's essential to undergo further evaluation, including laboratory tests and imaging studies, to confirm the diagnosis and determine the appropriate course of treatment.\",\n          \"I'm sorry to hear about your symptoms. Based on your history and test results, it's possible that you have primary hyperparathyroidism, which can be caused by conditions such as parathyroid adenoma or, more rarely, parathyroid carcinoma. Given the findings of a hypoechoic nodule on thyroid ultrasound and increased uptake on sestamibi scan, there may be an aberrant parathyroid gland involved. Surgery may be necessary for management, especially in symptomatic patients or those with specific indications like markedly elevated PTH levels, as in your case. If you have any further questions or concerns, please don't hesitate to ask.\",\n          \"Based on your symptoms and imaging findings, it's possible that you have hepatocellular carcinoma (HCC) and cirrhosis of the liver. Further evaluation, such as transarterial chemoembolization (TACE), may be necessary to manage the condition.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          \"Hello doctor, I recently returned from a trip to the Philippines where I consumed raw pork. Since then, I've been experiencing fever, diaphoresis, headache, nausea, and anorexia. My symptoms started three days after consuming the pork, and despite being prescribed doxycycline, they have persisted. I was eventually admitted to a local hospital with a fever, nuchal rigidity, headache, and malaise. Can you help me understand what might be going on?\",\n          \"Hello doctor, I've been experiencing left-sided neck and shoulder pain, and I recently underwent some tests that showed elevated calcium and parathyroid hormone levels. Could you help me understand what might be causing this pain?\",\n          \"Hello doctor, I've been experiencing right upper quadrant pain and weight loss, and imaging revealed liver masses. I'm also a hepatitis B virus carrier. What could be causing these symptoms?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(validate_contexted)\n",
        "val_df = pd.DataFrame.from_records(validate_contexted, columns=columns)\n",
        "val_df.head(5)"
      ],
      "metadata": {
        "id": "JSvbSmXsVNWn",
        "outputId": "0e860463-2276-491f-ccf0-3c12f93ad136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            response  \\\n",
              "0  Thank you for sharing the case details. Long-t...   \n",
              "1  Thank you for sharing the details of the case....   \n",
              "2  Thank you for sharing the details of the case....   \n",
              "3  Thank you for sharing the details. Pyoderma ga...   \n",
              "4  Thank you for sharing the details. It's crucia...   \n",
              "\n",
              "                                             context  \n",
              "0  Hello doctor, I have a case involving a 65-yea...  \n",
              "1  Hello doctor, I have a case involving a 58-yea...  \n",
              "2  Hello doctor, I have a case involving a 53-yea...  \n",
              "3  Hi doctor, I have a case involving a 66-year-o...  \n",
              "4  Hello doctor, I have a patient case involving ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb07d8e1-4870-4618-98ce-3f71bca6694b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thank you for sharing the case details. Long-t...</td>\n",
              "      <td>Hello doctor, I have a case involving a 65-yea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thank you for sharing the details of the case....</td>\n",
              "      <td>Hello doctor, I have a case involving a 58-yea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Thank you for sharing the details of the case....</td>\n",
              "      <td>Hello doctor, I have a case involving a 53-yea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thank you for sharing the details. Pyoderma ga...</td>\n",
              "      <td>Hi doctor, I have a case involving a 66-year-o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Thank you for sharing the details. It's crucia...</td>\n",
              "      <td>Hello doctor, I have a patient case involving ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb07d8e1-4870-4618-98ce-3f71bca6694b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb07d8e1-4870-4618-98ce-3f71bca6694b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb07d8e1-4870-4618-98ce-3f71bca6694b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c52fa92b-b46d-4bdd-8c33-e5624e96cbb5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c52fa92b-b46d-4bdd-8c33-e5624e96cbb5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c52fa92b-b46d-4bdd-8c33-e5624e96cbb5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "val_df",
              "summary": "{\n  \"name\": \"val_df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Thank you for sharing the case details. Managing PRES syndrome in the postpartum period involves controlling blood pressure, preventing seizures, and addressing any underlying conditions such as preeclampsia or HELLP syndrome. Treatment may include magnesium sulfate for seizure prevention, antihypertensive medications, and supportive measures like fluid management and transfusions. Long-term follow-up and monitoring for resolution of cerebral edema, as seen in the MRI, are essential. If you have further questions or need assistance, feel free to ask.\",\n          \"Thank you for sharing the case details. Given the presence of liver metastasis from the primary renal carcinoid tumor, further evaluation and management are warranted. This may include imaging studies to assess the extent of metastatic disease, such as CT or MRI of the abdomen and pelvis, and consideration of systemic therapy options like somatostatin analogs or targeted therapies. Multidisciplinary consultation with oncology specialists is recommended to develop an appropriate treatment plan tailored to the patient's individual case. If you have any additional questions or concerns, feel free to ask.\",\n          \"Thank you for sharing the case details. Long-term calcium tablet intake, as seen in this patient with a history of osteoporosis, can lead to the development of calcified masses, such as fibrovascular polyps, in the esophagus. These masses may present with dysphagia and weight loss, as observed in this case. Endoscopic removal is often the preferred management approach, as in this case, to alleviate symptoms and prevent complications. Regular follow-up is essential to monitor for recurrence or complications. Additionally, patients should be advised on the potential risks associated with long-term calcium supplementation. If you have any further questions or concerns, feel free to ask.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Doctor, I have a case involving a 31-year-old woman admitted for an elective cesarean section at 38 weeks gestation. She experienced hypertensive peaks during spinal anesthesia, followed by severe postpartum headache and three generalized tonic-clonic convulsions. Lab findings showed features of HELLP syndrome. MRI revealed findings consistent with PRES syndrome secondary to severe postpartum preeclampsia. She was treated with magnesium sulfate, calcium channel blocker, antiepileptic, and transfusions. Can you provide insights on managing PRES syndrome in the postpartum period?\",\n          \"Doctor, I have a case of a 33-year-old man with a history of a well-differentiated neuroendocrine (carcinoid) tumor confined to the left kidney, who underwent radical nephrectomy. Nine years later, he presented with a cystic liver mass and multiple high-density shadows in the gallbladder. Cholecystectomy and extirpation for hepatic cyst were performed, and histologic examination revealed features consistent with a neuroendocrine tumor. Can you provide guidance on the management and further evaluation of this patient?\",\n          \"Hello doctor, I have a case involving a 65-year-old female presenting with progressive dysphagia and weight loss. Upper gastrointestinal endoscopy revealed a 4 cm esophageal mass with an ulcerated mucosa. Upper gastrointestinal series and CT scan confirmed the presence of an ovoid calcified mass with smooth contours and esophageal diverticula. Biopsies showed inflammatory cells but no malignancy. The mass was removed endoscopically and identified as a fibrovascular polyp with calcifications, possibly related to long-term calcium tablet intake. The patient is now asymptomatic, but could you discuss the significance of calcium tablet intake in the development of esophageal masses and the management of such cases?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training and Evaluating**"
      ],
      "metadata": {
        "id": "gX5UfqDXbs4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args, train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer) -> Tuple[int, float]:\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer = SummaryWriter()\n",
        "\n",
        "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
        "\n",
        "    def collate(examples: List[torch.Tensor]):\n",
        "        if tokenizer._pad_token is None:\n",
        "            return pad_sequence(examples, batch_first=True)\n",
        "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=collate, drop_last = True\n",
        "    )\n",
        "\n",
        "    if args.max_steps > 0:\n",
        "        t_total = args.max_steps\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    model = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    # add_special_tokens_(model, tokenizer)\n",
        "\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "\n",
        "    # Check if saved optimizer or scheduler states exist\n",
        "    if (\n",
        "        args.model_name_or_path\n",
        "        and os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\"))\n",
        "        and os.path.isfile(os.path.join(args.model_name_or_path, \"scheduler.pt\"))\n",
        "    ):\n",
        "        # Load in optimizer and scheduler states\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
        "\n",
        "    if args.fp16:\n",
        "        try:\n",
        "            from apex import amp\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
        "\n",
        "    # multi-gpu training (should be after apex fp16 initialization)\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Distributed training (should be after apex fp16 initialization)\n",
        "    if args.local_rank != -1:\n",
        "        model = torch.nn.parallel.DistributedDataParallel(\n",
        "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n",
        "        )\n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
        "    logger.info(\n",
        "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
        "        args.train_batch_size\n",
        "        * args.gradient_accumulation_steps\n",
        "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
        "    )\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    epochs_trained = 0\n",
        "    steps_trained_in_current_epoch = 0\n",
        "    # Check if continuing training from a checkpoint\n",
        "    if args.model_name_or_path and os.path.exists(args.model_name_or_path):\n",
        "        try:\n",
        "            # set global_step to gobal_step of last saved checkpoint from model path\n",
        "            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n",
        "            global_step = int(checkpoint_suffix)\n",
        "            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "\n",
        "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
        "            logger.info(\"  Continuing training from global step %d\", global_step)\n",
        "            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
        "        except ValueError:\n",
        "            logger.info(\"  Starting fine-tuning.\")\n",
        "\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "\n",
        "    model.zero_grad()\n",
        "    train_iterator = trange(\n",
        "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n",
        "    )\n",
        "    set_seed(args)  # Added here for reproducibility\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "\n",
        "            # Skip past any already trained steps if resuming training\n",
        "            if steps_trained_in_current_epoch > 0:\n",
        "                steps_trained_in_current_epoch -= 1\n",
        "                continue\n",
        "\n",
        "            inputs, labels = (batch, batch)\n",
        "            if inputs.shape[1] > 1024: continue\n",
        "            inputs = inputs.to(args.device)\n",
        "            labels = labels.to(args.device)\n",
        "            model.train()\n",
        "            outputs = model(inputs, labels=labels)\n",
        "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "\n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            if args.fp16:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                if args.fp16:\n",
        "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "                optimizer.step()\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    # Log metrics\n",
        "                    if (\n",
        "                        args.local_rank == -1 and args.evaluate_during_training\n",
        "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results = evaluate(args, model, tokenizer)\n",
        "                        for key, value in results.items():\n",
        "                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n",
        "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
        "                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                    checkpoint_prefix = \"checkpoint\"\n",
        "                    # Save model checkpoint\n",
        "                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n",
        "                    os.makedirs(output_dir, exist_ok=True)\n",
        "                    model_to_save = (\n",
        "                        model.module if hasattr(model, \"module\") else model\n",
        "                    )  # Take care of distributed/parallel training\n",
        "                    model_to_save.save_pretrained(output_dir)\n",
        "                    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "                    _rotate_checkpoints(args, checkpoint_prefix)\n",
        "\n",
        "                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
        "\n",
        "            if args.max_steps > 0 and global_step > args.max_steps:\n",
        "                epoch_iterator.close()\n",
        "                break\n",
        "        if args.max_steps > 0 and global_step > args.max_steps:\n",
        "            train_iterator.close()\n",
        "            break\n",
        "\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer.close()\n",
        "\n",
        "    return global_step, tr_loss / global_step\n",
        "\n",
        "# Evaluation of some model\n",
        "\n",
        "def evaluate(args, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, df_trn, df_val, prefix=\"\") -> Dict:\n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "    eval_output_dir = args.output_dir\n",
        "\n",
        "    eval_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=True)\n",
        "    os.makedirs(eval_output_dir, exist_ok=True)\n",
        "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "    # Note that DistributedSampler samples randomly\n",
        "\n",
        "    def collate(examples: List[torch.Tensor]):\n",
        "        if tokenizer._pad_token is None:\n",
        "            return pad_sequence(examples, batch_first=True)\n",
        "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate, drop_last = True\n",
        "    )\n",
        "\n",
        "    # multi-gpu evaluate\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    model.eval()\n",
        "\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        inputs, labels = (batch, batch)\n",
        "        inputs = inputs.to(args.device)\n",
        "        labels = labels.to(args.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, labels=labels)\n",
        "            lm_loss = outputs[0]\n",
        "            eval_loss += lm_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    perplexity = torch.exp(torch.tensor(eval_loss))\n",
        "\n",
        "    result = {\"perplexity\": perplexity}\n",
        "\n",
        "    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "\n",
        "    return result\n",
        ""
      ],
      "metadata": {
        "id": "ugpJmjwDbuQW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training**"
      ],
      "metadata": {
        "id": "YnCs_mMtcVdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(df_trn, df_val):\n",
        "    args = Args()\n",
        "\n",
        "    if args.should_continue:\n",
        "        sorted_checkpoints = _sorted_checkpoints(args)\n",
        "        if len(sorted_checkpoints) == 0:\n",
        "            raise ValueError(\"Used --should_continue but no checkpoint was found in --output_dir.\")\n",
        "        else:\n",
        "            args.model_name_or_path = sorted_checkpoints[-1]\n",
        "\n",
        "    if (\n",
        "        os.path.exists(args.output_dir)\n",
        "        and os.listdir(args.output_dir)\n",
        "        and args.do_train\n",
        "        and not args.overwrite_output_dir\n",
        "        and not args.should_continue\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
        "                args.output_dir\n",
        "            )\n",
        "        )\n",
        "        # Setup CUDA, GPU & distributed training\n",
        "    device = torch.device(\"cuda\")\n",
        "    args.n_gpu = torch.cuda.device_count()\n",
        "    args.device = device\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
        "    )\n",
        "    logger.warning(\n",
        "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        args.local_rank,\n",
        "        device,\n",
        "        args.n_gpu,\n",
        "        bool(args.local_rank != -1),\n",
        "        args.fp16,\n",
        "    )\n",
        "# Set seed\n",
        "    set_seed(args)\n",
        "\n",
        "    config = AutoConfig.from_pretrained(args.config_name, cache_dir=args.cache_dir)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n",
        "    model = AutoModelWithLMHead.from_pretrained(\n",
        "        args.model_name_or_path,\n",
        "        from_tf=False,\n",
        "        config=config,\n",
        "        cache_dir=args.cache_dir,\n",
        "    )\n",
        "    model.to(args.device)\n",
        "\n",
        "    logger.info(\"Training/evaluation parameters %s\", args)\n",
        "\n",
        "    # Training\n",
        "    if args.do_train:\n",
        "        train_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False)\n",
        "\n",
        "        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
        "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n",
        "    if args.do_train:\n",
        "        # Create output directory if needed\n",
        "        os.makedirs(args.output_dir, exist_ok=True)\n",
        "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        model_to_save = (\n",
        "            model.module if hasattr(model, \"module\") else model\n",
        "        )  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(args.output_dir)\n",
        "        tokenizer.save_pretrained(args.output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
        "\n",
        "        # Load a trained model and vocabulary that you have fine-tuned\n",
        "        model = AutoModelWithLMHead.from_pretrained(args.output_dir)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n",
        "        model.to(args.device)\n",
        "# Evaluation\n",
        "    results = {}\n",
        "    if args.do_eval and args.local_rank in [-1, 0]:\n",
        "        checkpoints = [args.output_dir]\n",
        "        if args.eval_all_checkpoints:\n",
        "            checkpoints = list(\n",
        "                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
        "            )\n",
        "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "        for checkpoint in checkpoints:\n",
        "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
        "            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
        "\n",
        "            model = AutoModelWithLMHead.from_pretrained(checkpoint)\n",
        "            model.to(args.device)\n",
        "            result = evaluate(args, model, tokenizer, df_trn, df_val, prefix=prefix)\n",
        "            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
        "            results.update(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "main(trn_df, val_df)"
      ],
      "metadata": {
        "id": "6kiKY_fecV5x",
        "outputId": "f4c28743-c1f0-45a2-8e21-6f4521eff342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Process rank: -1, device: cuda, n_gpu: 0, distributed training: False, 16-bits training: False\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-e35d97f66a32>\u001b[0m in \u001b[0;36m<cell line: 106>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-e35d97f66a32>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(df_trn, df_val)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     )\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training/evaluation parameters %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2593\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2594\u001b[0m                 )\n\u001b[0;32m-> 2595\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1157\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Testing**"
      ],
      "metadata": {
        "id": "3QIX9OxCdNOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_test = open(\"/content/drive/MyDrive/data/test_data.json\")\n",
        "test_data = json.load(f_test)\n",
        "f_test.close()\n",
        "\n",
        "test_query = []\n",
        "test_response = []\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "  test_response.append(test_data[i][1])\n",
        "  test_query.append(test_data[i][0])\n",
        "\n",
        "print(len(test_response))\n",
        "print(len(test_query))"
      ],
      "metadata": {
        "id": "_0a2aby6dQHm",
        "outputId": "0c6a8784-d5a0-4504-f271-b9a1949b582a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_chatbot = []\n",
        "\n",
        "for i in range(len(test_query)):\n",
        "  tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
        "  model = AutoModelWithLMHead.from_pretrained('/content/drive/MyDrive/output-small-save', from_tf=True)\n",
        "  # append the new user input tokens to the chat history\n",
        "  bot_input_ids = tokenizer.encode(test_query[i] + tokenizer.eos_token, return_tensors='pt')\n",
        "  print(\"Patient: {} \\n\".format(test_query[i]))\n",
        "  print(\"Reference:  {} \\n\".format(test_response[i]))\n",
        "\n",
        "\n",
        "  # generated a response while limiting the total chat history to 1000 tokens,\n",
        "  chat_history_ids = model.generate(\n",
        "      bot_input_ids, max_length=100,\n",
        "      pad_token_id=tokenizer.eos_token_id,\n",
        "      no_repeat_ngram_size=3,\n",
        "      do_sample=True,\n",
        "      top_k=10,\n",
        "      top_p=0.7,\n",
        "      temperature = 0.8\n",
        "  )\n",
        "\n",
        "  # pretty print last ouput tokens from bot\n",
        "  print(\"Predict: {} \\n\\n\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n",
        "  test_chatbot.append(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True))\n",
        "\n",
        "print(len(test_chatbot))"
      ],
      "metadata": {
        "id": "akdf41cadeYo",
        "outputId": "a7676de8-9484-499a-c81b-5a1678cdaa5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hello doctor, I have a case regarding a 71-year-old African-American woman with worsening exertional dyspnoea, orthopnoea, and lower extremity oedema. She has a history of hypertension and G6PD deficiency. Examination revealed signs of heart failure, including jugular venous distension, crackles in lung bases, and cardiomegaly on chest radiography. Echocardiography showed a dilated left ventricle with reduced ejection fraction and mild right ventricular dysfunction. Coronary artery catheterisation was normal. Treatment with ethacrynic acid, spironolactone, metoprolol succinate, and losartan resulted in resolution of pulmonary oedema. However, I'm curious about the long-term management plan for her heart failure considering her G6PD deficiency. \n",
            "\n",
            "Reference:  Thank you for sharing the case details. The long-term management of heart failure in this patient will involve optimizing medication therapy to improve symptoms and prolong survival. We need to consider her G6PD deficiency when selecting medications, as certain drugs may exacerbate haemolysis in individuals with this condition. The medications chosen, such as ethacrynic acid, spironolactone, metoprolol succinate, and losartan, are less likely to cause haemolysis. Regular monitoring of renal function, electrolytes, and cardiac function will be crucial for assessing treatment response and adjusting medications as needed. If you have any specific concerns or questions, feel free to ask. \n",
            "\n",
            "Predict: akings \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hello doctor, I have a case involving a 65-year-old woman with a history of idiopathic BCS who presented with worsening right upper quadrant pain. Imaging revealed a saccular aneurysm in the extrahepatic portal vein, likely associated with BCS progression. Despite no ascites or variceal bleeding, a decision was made to create a TIPS due to increasing pain and concern for complications from the aneurysm. The procedure was successful, and the patient's pain resolved completely. She was discharged on long-term warfarin and remained asymptomatic after 1 year of follow-up. Can you provide further insight into the management of BCS-related complications like this aneurysm? \n",
            "\n",
            "Reference:  Thank you for sharing the case details. Management of BCS-related complications, such as portal vein aneurysms, often involves a multidisciplinary approach. In this case, TIPS placement was a suitable intervention to relieve hepatic venous outflow obstruction and address the aneurysm. Long-term anticoagulation with warfarin is essential to prevent thrombotic events, and regular follow-up imaging helps monitor for recurrence or progression of complications. Additionally, close collaboration between hepatology, interventional radiology, and vascular surgery teams is crucial for optimizing treatment strategies and ensuring favorable outcomes. If you have any specific questions or concerns, feel free to ask. \n",
            "\n",
            "Predict:  employ \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hello doctor, I have a case involving a 66-year-old female patient who presented with chest pain initially treated as acid reflux but later diagnosed with posterolateral ST elevation myocardial infarction. She underwent successful percutaneous intervention for an acutely occluded ramus intermedius vessel but subsequently developed cardiogenic shock due to severe mitral regurgitation from a ruptured papillary muscle. Despite maximal support, surgical intervention was necessary, and a mitral valve replacement was performed. The patient initially showed improvement but later succumbed to pneumonia and sepsis with multiorgan failure. Can you provide insights into the management of similar cases and potential strategies to improve outcomes? \n",
            "\n",
            "Reference:  Thank you for sharing the case details. Management of acute mitral regurgitation from papillary muscle rupture is challenging and often requires prompt surgical intervention. Early recognition and aggressive treatment of myocardial infarction-related complications, such as papillary muscle rupture, are crucial to improve outcomes. In high-risk cases like this, surgical repair or replacement of the mitral valve may be necessary to restore cardiac function. Close monitoring and appropriate postoperative care are essential to prevent complications and optimize recovery. Additionally, strategies to prevent and manage postoperative complications, such as pneumonia and sepsis, are important aspects of comprehensive patient care. If you have specific questions or concerns, feel free to ask. \n",
            "\n",
            "Predict:  Intelligence \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hello doctor, I have a case involving a 68-year-old woman with chronic obstructive pulmonary disease who underwent a right lower wedge resection for a pulmonary LCNEC in 2011. Approximately six months post-surgery, she developed dysphagia, and subsequent evaluations revealed achalasia. Despite treatment with calcium channel blockers, her symptoms worsened, and she presented with weight loss and progressive dysphagia in 2014. Further investigations revealed a metastatic LCNEC involving the esophagus. She underwent chemotherapy but unfortunately succumbed to the disease after six months. Can you provide insights into the management of LCNEC metastasis to the esophagus and potential treatment options? \n",
            "\n",
            "Reference:  Thank you for sharing the case details. LCNEC metastasis to the esophagus is rare and presents significant challenges in management. Treatment options often involve a multidisciplinary approach, including chemotherapy, radiation therapy, and palliative interventions to alleviate symptoms. However, prognosis is generally poor due to the aggressive nature of LCNEC. In cases of metastatic disease, the focus may shift towards supportive care and improving quality of life. It's essential to discuss treatment goals and options with the patient and their family, taking into account their preferences and overall health status. If you have specific questions or concerns, feel free to ask. \n",
            "\n",
            "Predict: agnar \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hello doctor, I have a case involving a woman in her early 70s who presented to our emergency room with substernal chest pain, diaphoresis, and dyspnea 30 minutes after her husband's death from an out-of-hospital cardiac arrest. She has a history of hypertension and hypothyroidism and was on oral furosemide and levothyroxine. On examination, she was in distress with elevated jugular venous distention and cardiac enzymes were elevated. ECG showed ST-segment elevations suggestive of an anterior wall infarct. Echocardiogram revealed reduced ejection fraction and akinesis of certain segments. Coronary angiography showed non-obstructive disease. She was started on antiplatelet therapy and heart failure medications and discharged in stable condition. Can you provide further insights into the management and prognosis of her condition? \n",
            "\n",
            "Reference:  Thank you for sharing the details. Management of acute coronary syndrome in the setting of stress cardiomyopathy or takotsubo cardiomyopathy involves antiplatelet therapy to prevent further thrombosis, along with initiation of heart failure medications to improve cardiac function and reduce symptoms. Prognosis varies depending on factors such as the extent of myocardial damage and the presence of underlying comorbidities. In some cases, recovery of cardiac function can be rapid and complete, as seen in this patient's follow-up echocardiogram. However, long-term outcomes may require ongoing monitoring and management to prevent recurrence or complications. If you have specific questions or concerns, feel free to ask. \n",
            "\n",
            "Predict:  Sync \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hello doctor, I have a case involving a 36-year-old Sri Lankan male who presented with fever, arthralgia, and myalgia for one day, along with mild dysuria. He had a history of previous leptospirosis treatment. On examination, he was afebrile but hypotensive with tachycardia. Initial investigations showed leukocytosis, thrombocytopenia, and microscopic hematuria, consistent with a diagnosis of leptospirosis. However, on the second day of illness, he developed severe myocarditis, leading to hypotension, dyspnea, and atrial fibrillation. Despite treatment with antibiotics, inotropes, and corticosteroids, he developed refractory shock and died. Can you provide insights into the management of severe leptospirosis complicated by myocarditis and its prognosis? \n",
            "\n",
            "Reference:  Thank you for sharing the details. Management of severe leptospirosis with myocarditis involves aggressive supportive care, including intravenous antibiotics to target the underlying infection, inotropes to support cardiac function, and corticosteroids to mitigate inflammation. Prognosis depends on various factors, including the extent of myocardial damage and the response to treatment. Despite optimal therapy, some cases may progress to refractory shock and carry a poor prognosis. It's essential to monitor closely for complications and provide timely interventions. If you have specific questions or concerns, feel free to ask. \n",
            "\n",
            "Predict: De \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hello doctor, I have a case involving a 35-year-old woman presenting with headache, blocked left-sided nasal canal, and epistaxis for 2 years, along with secondary amenorrhea for the past 19 years. Nasal examination revealed a left-sided choanal mass, and MRI showed a sellar and infra-sellar mass extending into the nasopharynx. Her serum prolactin levels were significantly elevated at 7443 µg/L, with other pituitary hormones within normal limits. A diagnosis of giant prolactinoma was made, and she was prescribed cabergoline. Can you provide further insights into the management of giant prolactinomas and the associated risks of cabergoline? \n",
            "\n",
            "Reference:  Thank you for sharing the details. Management of giant prolactinomas typically involves treatment with dopamine agonists like cabergoline to reduce prolactin levels and shrink the tumor. Cabergoline is generally well-tolerated, but potential risks include nausea, dizziness, and rarely, cardiac valve disorders and fibrosis. Regular monitoring of prolactin levels and tumor size is essential to assess treatment response and adjust therapy as needed. Additionally, patient education on medication adherence and follow-up care is crucial. If you have any specific concerns or questions, feel free to ask. \n",
            "\n",
            "Predict:  bishops \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hello doctor, I have a case involving a 38-year-old woman who presented with severe abdominal pain, intermittent bloody diarrhea, and multiple perforations in the sigmoid colon, descending colon, and transverse colon. Pathology revealed well-organized thrombi and intimal proliferation within some vessels, marked acute peritonitis, and multiple ulcers. Can you provide further insights into the diagnosis and management of this condition? \n",
            "\n",
            "Reference:  Thank you for sharing the details. Based on the clinical presentation and findings, it appears that the patient likely had a severe form of inflammatory bowel disease (IBD) such as Crohn's disease or ulcerative colitis. The presence of recurrent oral and genital aphthous ulcers, positive pathergy test, and extensive thrombus within the inferior vena cava suggest a diagnosis of Behçet's disease. Management typically involves a combination of corticosteroids, immunosuppressive therapy, and anticoagulants for thrombosis. Surgical intervention may be necessary in cases of perforation. Regular follow-up and monitoring are crucial for disease management and prevention of complications. If you have any specific questions or concerns, feel free to ask. \n",
            "\n",
            "Predict:  ridiculouslyexprexpr threads NOTICE whiff OttawaTeria{ formations \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hello doctor, I have a case involving a 38-year-old Caucasian man with EvC syndrome, presenting with missing lower incisors, disproportionately short extremities, mild mental retardation, and a history of ostium primum atrial septal defect closure and cavotricuspid isthmus ablation for common atrial flutter. He now presents with a high-pitched systolic murmur, dilated and hypertrophic left ventricle, severe mitral valve regurgitation, and elevated pulmonary artery pressure. Mitral valve surgery was scheduled, and a bileaflet mechanical valve was implanted. Can you provide further insights into the diagnosis, management, and prognosis of this condition? \n",
            "\n",
            "Reference:  Thank you for sharing the details. Given the patient's clinical features, including the morphological abnormalities consistent with EvC syndrome and the cardiac manifestations, it's crucial to manage the cardiovascular complications effectively. In this case, mitral valve surgery was warranted due to severe mitral valve regurgitation and elevated pulmonary artery pressure. The successful implantation of a bileaflet mechanical valve is a positive outcome, and the optimal function of the mitral valve observed during follow-up is encouraging. Continued monitoring and management are essential to ensure the long-term success of the intervention. If you have any specific questions or concerns, feel free to ask. \n",
            "\n",
            "Predict:  Semin \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hi doctor, I have a case involving a 21-year-old man with symptoms of intermittent fever, headache, polyarthralgias, skin rash, and petechiae. Initial evaluation revealed elevated inflammatory markers and mild pericardial effusion. Subsequently, he developed dyspnea, diffuse chest pain, and increased pericardial effusion, leading to emergency pericardiocentesis and thoracocentesis. A diagnosis of AOSD was established, and treatment with prednisone resulted in significant improvement. However, there was recurrence of effusion after corticosteroid withdrawal. Can you provide insights into the management and prognosis of AOSD in such cases? \n",
            "\n",
            "Reference:  Thank you for sharing the details. AOSD is a rare systemic inflammatory disorder characterized by fever, arthritis, skin rash, and other systemic symptoms. Management typically involves corticosteroids and other immunosuppressive agents to control inflammation and prevent complications such as pericardial effusion. Prognosis varies, but long-term remission can be achieved with appropriate treatment. Recurrence of symptoms, as seen in this case, may require ongoing medication and monitoring to prevent relapses. Regular follow-up visits and evaluation of inflammatory markers and imaging studies are important for assessing disease activity and adjusting treatment as needed. If you have any specific concerns or questions, feel free to ask. \n",
            "\n",
            "Predict:  appointing \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hello doctor, I have a case involving an 11-year-old boy with headaches and vomiting for several months. MRI revealed a large prepontine mass causing hydrocephalus. He underwent surgery with complete resection of the tumour, resulting in temporary oculomotor nerve palsy that resolved within 4 weeks. Follow-up MRI scans showed no recurrence, and histopathological examination suggested chordoma. Can you provide insights into the long-term management and prognosis for this patient? \n",
            "\n",
            "Reference:  Thank you for sharing the details. Chordomas are rare tumors that arise from remnants of the notochord. Complete surgical resection is the primary treatment, and in this case, it was successful without the need for postoperative radiation therapy. Long-term management typically involves regular follow-up with imaging studies to monitor for recurrence. The prognosis can vary depending on factors such as the extent of resection and histological characteristics of the tumor. In cases of complete resection like this one, the prognosis is generally favorable, but continued surveillance is important. If you have any specific concerns or questions, feel free to ask. \n",
            "\n",
            "Predict:  Burnett \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hello doctor, I have a case involving a 25-year-old female patient with left-sided visual loss, amenorrhea, and right hemiparesis. Imaging revealed a large pituitary tumor with exceedingly high serum prolactin levels. Despite treatment with cabergoline and surgical debulking, the prolactin level remained elevated. Can you provide insights into further management options and prognosis for this patient? \n",
            "\n",
            "Reference:  Thank you for sharing the details. Given the persistent elevation of serum prolactin levels despite cabergoline therapy and surgical debulking, additional treatment options may include radiation therapy or consideration of alternative medications such as bromocriptine or quinagolide. The prognosis for patients with prolactin-producing pituitary adenomas can vary depending on factors such as tumor size, invasiveness, and response to treatment. Close monitoring with regular imaging and hormonal assessments will be essential to evaluate response to treatment and detect any recurrence. If you have any specific questions or concerns, feel free to ask. \n",
            "\n",
            "Predict:  limitingא PeerManagementkay civilization� civilization ZhuTED Dry obscene TED \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hello doctor, I have a case involving a 62-year-old male with a history of dyspnea on exertion, lower extremity edema, abdominal bloating, tastelessness, weight loss, and neurological symptoms such as paresthesias, erectile dysfunction, and chronic diarrhea. Physical examination revealed hypotension, jugular venous distention, hepatomegaly, lower extremity edema, and neurological deficits suggestive of sensory-motor neuropathy. Laboratory tests, including NT-proBNP, nerve conduction studies, electromyography, ECG, and echocardiography, indicated cardiac involvement consistent with cardiac amyloidosis. Serum λ light-chain concentration was elevated, and rectum biopsy confirmed amyloid infiltrate, leading to a diagnosis of AL amyloidosis. Despite chemotherapy and supportive therapy, the patient's condition continued to deteriorate, and he passed away at home 3 months after diagnosis. Can you provide insights into the prognosis for patients with AL amyloidosis and discuss potential treatment options? \n",
            "\n",
            "Reference:  Thank you for sharing the details. AL amyloidosis carries a variable prognosis depending on factors such as the extent of organ involvement, response to treatment, and presence of comorbidities. Unfortunately, patients with advanced cardiac involvement, as seen in this case, often have a poorer prognosis. Treatment options for AL amyloidosis may include chemotherapy regimens targeting the underlying plasma cell dyscrasia, such as melphalan and dexamethasone, along with immunomodulatory agents like lenalidomide. Supportive therapy to manage symptoms and complications, such as fluid retention and diarrhea, is also crucial. However, despite treatment, disease progression and mortality can occur, as was the case with this patient. Close monitoring and individualized management are essential to optimize outcomes in patients with AL amyloidosis. If you have any further questions or concerns, feel free to ask. \n",
            "\n",
            "Predict: frac \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hi doctor, I'm presenting a case of a 56-year-old man with a 2-year history of dysphagia who was diagnosed with middle thoracic esophageal squamous cell carcinoma. A chest CT scan revealed an enlarged azygos vein, and an abdominal CT scan showed a defect in the inferior vena cava with direct drainage of the hepatic vein into the right atrium. We opted for a McKeown esophagectomy after consultation with the thoracic surgery and anesthesia departments. During surgery, we used a veno-venous bypass with real-time pressure monitoring to safely dissociate the tumor from the azygos vein without complications. The patient had an uneventful postoperative recovery and showed no signs of recurrent disease after 5 months of follow-up. Could you discuss the significance of using a veno-venous bypass in this procedure and the importance of real-time pressure monitoring? \n",
            "\n",
            "Reference:  Thank you for sharing the details of the case. The use of a veno-venous bypass during esophagectomy can help maintain hemodynamic stability by diverting blood flow away from the operative field, reducing the risk of venous congestion and potential complications such as hemorrhage or thrombosis. Real-time pressure monitoring of the femoral vein can provide valuable feedback on venous return and the effectiveness of the bypass, ensuring adequate perfusion to vital organs during the procedure. This monitoring allows for prompt adjustments as needed to optimize hemodynamics and minimize the risk of complications. In your case, the successful use of the veno-venous bypass with pressure monitoring likely contributed to the smooth surgical outcome and favorable postoperative recovery. If you have any further questions or concerns, feel free to ask. \n",
            "\n",
            "Predict: 239 \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the TF 2.0 model and are newly initialized: ['lm_head.weight', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: Hello doctor, I'm presenting a case of a 55-year-old woman referred to our hospital due to a suspicion of mediastinal tumor found incidentally on a medical-checkup plain X-ray. Chest MRI revealed a 3 cm diameter tumor connected to the right lobe of the thyroid and projecting into the mediastinum. Despite inconclusive results from a fine needle aspiration biopsy, 18F-FDG-PET showed high accumulation, raising concerns for malignancy. Consequently, a right lobe excision procedure for the thyroid gland was performed, revealing a tumor consistent with follicular thyroid adenoma upon histological examination. Given the unusual presentation, could you discuss the diagnostic challenges associated with mediastinal tumors originating from the thyroid gland? \n",
            "\n",
            "Reference:  Thank you for sharing the case details. Mediastinal tumors originating from the thyroid gland can present diagnostic challenges due to their rare occurrence and varied imaging characteristics. In this case, the initial suspicion based on chest X-ray and subsequent imaging modalities raised concerns for malignancy, prompting further investigation and surgical intervention. While fine needle aspiration biopsy is often considered the 'gold standard' for diagnosis, inconclusive results necessitated alternative diagnostic approaches, ultimately leading to surgical excision for definitive diagnosis. The importance of thorough evaluation and multidisciplinary collaboration in cases of suspected mediastinal tumors cannot be overstated. If you have any further questions or concerns, feel free to ask. \n",
            "\n",
            "Predict:  terminate \n",
            "\n",
            "\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
        "model = AutoModelWithLMHead.from_pretrained('/content/drive/MyDrive/output-small-save')\n",
        "\n",
        "# Let's chat for 5 lines\n",
        "for step in range(1):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
        "    # print(new_user_input_ids)\n",
        "\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens,\n",
        "    chat_history_ids = model.generate(\n",
        "        bot_input_ids, max_length=1000,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        no_repeat_ngram_size=3,\n",
        "        do_sample=True,\n",
        "        top_k=10,\n",
        "        top_p=0.7,\n",
        "        temperature = 0.8\n",
        "    )\n",
        "\n",
        "    # pretty print last ouput tokens from bot\n",
        "    print(\"Chatbot: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "UFseu7TeeG4q",
        "outputId": "05e4a257-54a3-4052-8590-408b638aeddb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/output-small-save were not used when initializing GPT2LMHeadModel: ['bert.embeddings.LayerNorm.bias', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at /content/drive/MyDrive/output-small-save and are newly initialized: ['h.0.attn.c_attn.bias', 'h.0.attn.c_attn.weight', 'h.0.attn.c_proj.bias', 'h.0.attn.c_proj.weight', 'h.0.ln_1.bias', 'h.0.ln_1.weight', 'h.0.ln_2.bias', 'h.0.ln_2.weight', 'h.0.mlp.c_fc.bias', 'h.0.mlp.c_fc.weight', 'h.0.mlp.c_proj.bias', 'h.0.mlp.c_proj.weight', 'h.1.attn.c_attn.bias', 'h.1.attn.c_attn.weight', 'h.1.attn.c_proj.bias', 'h.1.attn.c_proj.weight', 'h.1.ln_1.bias', 'h.1.ln_1.weight', 'h.1.ln_2.bias', 'h.1.ln_2.weight', 'h.1.mlp.c_fc.bias', 'h.1.mlp.c_fc.weight', 'h.1.mlp.c_proj.bias', 'h.1.mlp.c_proj.weight', 'h.10.attn.c_attn.bias', 'h.10.attn.c_attn.weight', 'h.10.attn.c_proj.bias', 'h.10.attn.c_proj.weight', 'h.10.ln_1.bias', 'h.10.ln_1.weight', 'h.10.ln_2.bias', 'h.10.ln_2.weight', 'h.10.mlp.c_fc.bias', 'h.10.mlp.c_fc.weight', 'h.10.mlp.c_proj.bias', 'h.10.mlp.c_proj.weight', 'h.11.attn.c_attn.bias', 'h.11.attn.c_attn.weight', 'h.11.attn.c_proj.bias', 'h.11.attn.c_proj.weight', 'h.11.ln_1.bias', 'h.11.ln_1.weight', 'h.11.ln_2.bias', 'h.11.ln_2.weight', 'h.11.mlp.c_fc.bias', 'h.11.mlp.c_fc.weight', 'h.11.mlp.c_proj.bias', 'h.11.mlp.c_proj.weight', 'h.2.attn.c_attn.bias', 'h.2.attn.c_attn.weight', 'h.2.attn.c_proj.bias', 'h.2.attn.c_proj.weight', 'h.2.ln_1.bias', 'h.2.ln_1.weight', 'h.2.ln_2.bias', 'h.2.ln_2.weight', 'h.2.mlp.c_fc.bias', 'h.2.mlp.c_fc.weight', 'h.2.mlp.c_proj.bias', 'h.2.mlp.c_proj.weight', 'h.3.attn.c_attn.bias', 'h.3.attn.c_attn.weight', 'h.3.attn.c_proj.bias', 'h.3.attn.c_proj.weight', 'h.3.ln_1.bias', 'h.3.ln_1.weight', 'h.3.ln_2.bias', 'h.3.ln_2.weight', 'h.3.mlp.c_fc.bias', 'h.3.mlp.c_fc.weight', 'h.3.mlp.c_proj.bias', 'h.3.mlp.c_proj.weight', 'h.4.attn.c_attn.bias', 'h.4.attn.c_attn.weight', 'h.4.attn.c_proj.bias', 'h.4.attn.c_proj.weight', 'h.4.ln_1.bias', 'h.4.ln_1.weight', 'h.4.ln_2.bias', 'h.4.ln_2.weight', 'h.4.mlp.c_fc.bias', 'h.4.mlp.c_fc.weight', 'h.4.mlp.c_proj.bias', 'h.4.mlp.c_proj.weight', 'h.5.attn.c_attn.bias', 'h.5.attn.c_attn.weight', 'h.5.attn.c_proj.bias', 'h.5.attn.c_proj.weight', 'h.5.ln_1.bias', 'h.5.ln_1.weight', 'h.5.ln_2.bias', 'h.5.ln_2.weight', 'h.5.mlp.c_fc.bias', 'h.5.mlp.c_fc.weight', 'h.5.mlp.c_proj.bias', 'h.5.mlp.c_proj.weight', 'h.6.attn.c_attn.bias', 'h.6.attn.c_attn.weight', 'h.6.attn.c_proj.bias', 'h.6.attn.c_proj.weight', 'h.6.ln_1.bias', 'h.6.ln_1.weight', 'h.6.ln_2.bias', 'h.6.ln_2.weight', 'h.6.mlp.c_fc.bias', 'h.6.mlp.c_fc.weight', 'h.6.mlp.c_proj.bias', 'h.6.mlp.c_proj.weight', 'h.7.attn.c_attn.bias', 'h.7.attn.c_attn.weight', 'h.7.attn.c_proj.bias', 'h.7.attn.c_proj.weight', 'h.7.ln_1.bias', 'h.7.ln_1.weight', 'h.7.ln_2.bias', 'h.7.ln_2.weight', 'h.7.mlp.c_fc.bias', 'h.7.mlp.c_fc.weight', 'h.7.mlp.c_proj.bias', 'h.7.mlp.c_proj.weight', 'h.8.attn.c_attn.bias', 'h.8.attn.c_attn.weight', 'h.8.attn.c_proj.bias', 'h.8.attn.c_proj.weight', 'h.8.ln_1.bias', 'h.8.ln_1.weight', 'h.8.ln_2.bias', 'h.8.ln_2.weight', 'h.8.mlp.c_fc.bias', 'h.8.mlp.c_fc.weight', 'h.8.mlp.c_proj.bias', 'h.8.mlp.c_proj.weight', 'h.9.attn.c_attn.bias', 'h.9.attn.c_attn.weight', 'h.9.attn.c_proj.bias', 'h.9.attn.c_proj.weight', 'h.9.ln_1.bias', 'h.9.ln_1.weight', 'h.9.ln_2.bias', 'h.9.ln_2.weight', 'h.9.mlp.c_fc.bias', 'h.9.mlp.c_fc.weight', 'h.9.mlp.c_proj.bias', 'h.9.mlp.c_proj.weight', 'lm_head.weight', 'ln_f.bias', 'ln_f.weight', 'wpe.weight', 'wte.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> User:Hello doctor, I have a case regarding a 71-year-old African-American woman with worsening exertional dyspnoea, orthopnoea, and lower extremity oedema. She has a history of hypertension and G6PD deficiency. Examination revealed signs of heart failure, including jugular venous distension, crackles in lung bases, and cardiomegaly on chest radiography. Echocardiography showed a dilated left ventricle with reduced ejection fraction and mild right ventricular dysfunction. Coronary artery catheterisation was normal. Treatment with ethacrynic acid, spironolactone, metoprolol succinate, and losartan resulted in resolution of pulmonary oedema. However, I'm curious about the long-term management plan for her heart failure considering her G6PD deficiency.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: forumsforums fabrication pets oppressed oppressed oppressed Sega Petsforumsforums critiquesstreamrestling Goal Goal Goal compressor Ukraine NAD rand Cable Goal Fiji compressor compressor Ukraine1998 omit¯¯yxOUROURCharles forcingogy Peoples bicycl Return Return harassedforums Holo Carth Carth Carth whip gren Cassidy perpet perpet perpet brightly Pasadenareviewed perpet perpet mounting hither Goal Goal midfield descriptor Alps width Helmet OC Timeforumshander remnantsforums Elkforums distanceilded Harvard multic271fal Trap Vaughn$$$$forums test unprecedented NADOilAnimforumsafortoremBlueBlue whosemacash dynamically oppressed randomly randomly stunning Her Her Barcelona Rated gren63honCV UniqueOUROUR Appeals Appeals TDs trustees Please dexterforumsキ Repsquist Tysonelveelve oppressed oppressed Bedford Smoke weaponry Barcelona headsforumsキ Encyclopedia Encyclopedia 91 Carth bunny bunny inadvertforums dismorning Minute FuriousORT22002200 suitcase Students enlisted randomlyDa Bok NAD Liang Liang Goal Goal flagliterally Minute Minute unprecedentedOUR458 battle�OilVIDOUR lawsonding harassed compressor contractorslux brightly flagilan NAD harassed NAD NAD Tem Numerous Students harassed mitigation oppressed oppressedIUMOil Mori plans Support Support SupportStrong Moderate Moderate Conversion lineage gren gren BP apes969 consortium disreviewed perpet harassedproclaimedFirstGVGV Her Minute harassed Carth CarthGVGVforums oppressed oppressed CAS Barcelona Sw� Students compressor compressor TTL�forums helmetaylor Minute Liangproclaimed Reading acondingophers Goal GoalStrong harmon perpet lawfully JC Lawrence LedinetAnim Her Her harasseddeveloped Studentsprintf perpetOUR ketikkttp reduce Nadu grenfal trap interfering grendrive contradict distanceEmilyEmilyforums playbookforumsforumssing Effect Pets fiber perpet Bond Webs WebsCharlesFirst Generalproclaimedproclaimedantonforums grocer Barrier RIGHT Campbell Campbellindainda compressor compressorornings students Vampire flo Her Minute pets game Barcelona Endurancecheck harvestreviewedreviewed miserable fiber expressed Herforums Students136 Conclusion democracyinnesssqlagnar stomachshaped Webs � array trapcash flag hither hither perpet hy Café� grind b Randolph Carthdding perpet harassed gorilla dis disItershaped RowlinghurhurEmilyEmily battle dis tremend Bedford BedfordocentocentOil come % pasturedevelopedudoImmotropNintendoEXT hitherOUR miserable perpet perpet Casesforums oppressed� fabrication randomly perpet churn harmon harmon orig compressor compressor compressorNatural sufficient VampireConsider NAD NAD NAD thirst Campbell COMP Goalhon compressor compressorAnim HerIUM Lonely cerebral Students deniedATTocentINSonicdebug ECB Wra Minute�134 trapאא ~ snapping snapping 22 compressor compressor Stat Reps Manifest pasture MinuteNatural cited Return Xue Fault Pasadena Castle Goalproclaimedhonhonhon Interface Fault patriarchal Liangwu orientation Led immortal immortalrets Spaceforumsforums Num analog Asians Herm descriptor descriptor¯¯ Minute era mast crippled Goal pastureSaudiSaudi Anyone Anyone Students harassed harassed harassedproclaimedproclaimed Anderson Liang forcing TimeADSADS descriptorosp battle Minute qualifyingOilOil forcing subdued Students Students Students TDs mechanically compressor Ukraine� Students Students Ukraine fatal serve plankADSforums evidenced stomach Minute Pasadena Katz dean perpet racist 384 newspapers flag Krishna ConfederationOURIUM Lonely Wra garden purely consistent Casesforums keywordindainda plans$$$$ perpet racist Zeus Bond Return Webs Mori sealingOfficials equival TimeNaturaldeveloped eyebOUR grapproclaimedindainda inexperiencedproclaimed BondOil letudo Goal GoalCorp odds thirst Goal eyeb Goalithingithing NADOUROUR reusableinges Minuteforums Hobbit Nadu gren Fault counters cel Bardlowerlowerudo equival equival curated1998ICTosp forcingOUROUR battle battle miserable miserable Boughtét pregnant annotations ES Drink2200inda Xue dis harassed compressor compressor heavily Bed oppressed Bedford Bedfordigel perpetAsia Vampire perpetcoxOUROURforums LedAfter Waterloo perpet perpetforums Encyclopedia Numframes sitting plansestyles %bottomOUR fulfilledforums battle battle Space Space Spacependproclaimednic gren gren Tier Liang randomly trap hostagesproclaimed guides guides Leon consortium consortiumGV backyardAnim summers summers Led Led MinuteOUR AES AES AES captures mitigation mitigation perpetarry racist racistiansantlyirc fiber Liang Campbell Campbell Barcelona acMade disavOUR friOilsponsored median harassed Hill Hill cher Students orig compressorwalking Carth Carth Wra gayOUR Her sch schdeveloped �••removereviewedATTNatural residGb Minute Minute Krishna perpetOil compressor compressorhon battle battleforums reporterOUR harassed harassedonal BrownbermanSym CarthOUR Appeals nearforums21 Fault Liang multicCongratulations scathing elves HorizonOUR864 perliest zeal poolsversionhonhon Atlas landmark dogsshaped Returnproof Her Herinoisremove perpet Runs Minute harassedproclaimed Abraham Studentsoche harassed Faultproclaimedproclaimed Mrs PetsOUR Weaver trusteesNeither Minutesing wiped Des Holo Leon miserableSection Symptoms\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}